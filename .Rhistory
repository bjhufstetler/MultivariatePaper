accuracy(tb)
tb
boston = read.csv('boston.csv')
boston = read.csv('boston.csv')
str(boston)
# Plot observations
plot(boston$LON, boston$LAT)
# Tracts alongside the Charles River
points(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col="blue", pch=19)
# Plot pollution/NOX
summary(boston$NOX)
points(boston$LON[boston$NOX>=0.55], boston$LAT[boston$NOX>=0.55], col="green", pch=20)
# Plot prices
plot(boston$LON, boston$LAT)
summary(boston$MEDV)
#Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
#5.00   17.02   21.20   22.53   25.00   50.00
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col="red", pch=20)
# Load CART packages
library(rpart)
# install rpart package
#install.packages("rpart.plot")
library(rpart.plot)
# CART model
latlontree = rpart(MEDV ~ LAT + LON, data=boston)
# Plot the tree using prp command defined in rpart.plot package
prp(latlontree)
# Visualize output
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2],boston$LAT[boston$MEDV>=21.2], col="red", pch=20)
fittedvalues = predict(latlontree)
points(boston$LON[fittedvalues>21.2],boston$LAT[fittedvalues>=21.2], col="blue", pch="$")
#Simplifying Tree by increasing minbucket
latlontree = rpart(MEDV ~ LAT + LON, data=boston, minbucket=50)
plot(latlontree)
text(latlontree)
fittedvalues = predict(latlontree)
points(boston$LON[fittedvalues>21.2],boston$LAT[fittedvalues>=21.2], col="blue", pch="$")
# Visualize output
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2],boston$LAT[boston$MEDV>=21.2], col="red", pch=20)
fittedvalues = predict(latlontree)
points(boston$LON[fittedvalues>21.2],boston$LAT[fittedvalues>=21.2], col="blue", pch="$")
# Split the data
#install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(boston$MEDV, SplitRatio = 0.7)
train = subset(boston, split==TRUE)
test = subset(boston, split==FALSE)
# Making a Regression Tree Model
# Create a CART model
tree = rpart(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO, data=train)
prp(tree)
tree.pred = predict(tree, newdata=test)
tree.sse = sum((tree.pred - test$MEDV)^2)
tree.sse
# Now use the IRIS dataset to classify iris type using CART
# load the package
library(rpart)
# load data
data(iris)
# fit model
fit <- rpart(Species~., data=iris)
# summarize the fit
summary(fit)
# make predictions
predictions <- predict(fit, iris[,1:4], type="class")
# summarize accuracy
iris_pred <- table(predictions, iris$Species)
iris_pred
##check the accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(iris_pred)
# Install packages/library and read in data
#install.packages("kableExtra")
library(kableExtra)
library(knitr)
credit.df <- read.csv('credit.csv')
credit.df$default <- factor(credit.df$default, levels = c(1, 2), labels = c('Yes', 'No'))
#View and understand you data
str(credit.df)
summary(credit.df)
kable(head(credit.df, n=15), format="html") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
set.seed(1978)
credit.random.df <- credit.df[order(runif(1000)), ]
summary(credit.df$amount)
summary(credit.random.df$amount)
credit.train <- credit.random.df[1:900, ]
credit.test <- credit.random.df[901:1000, ]
prop.table(table(credit.train$default))
prop.table(table(credit.test$default))
library(C50)
credit.fit <- C5.0(credit.train[-17], credit.train$default)
credit.fit
summary(credit.fit)
dim(boston)
11+18+18+22+30+28+34+45
kable(head(credit.df, n=15), format="html") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
summary(credit.fit)
load("pmesi.RData")
summary(is.na(pmesi.final))
count(is.na(pmesi.final))
sum(is.na(pmesi.final))
6132*913
sum(is.na(pmesi.final))/(6132*913)
dim(pemsi)[1]
dim(pmesi.final)[2]
sum(is.na(pmesi.final))*100/(dim(pemsi.final)[1]*dim(pmesi.final)[2])
sum(is.na(pmesi.final))*100/(dim(pmesi.final)[1]*dim(pmesi.final)[2])
sum(is.na(pmesi.final$`Highest Level of Conflict Intensity`))
complete.cases(pmesi.final)
table(complete.cases(pmesi.final))
dim(pmesi.final)[2]
count.missing <- vector(NA, dim(pmesi.final)[2])
count.missing <- vector(, dim(pmesi.final)[2])
for i in count.missing{
count.missing[i] <- count(is.na(pmesi.final)[,i])
}
for i in (1:dim(pmesi.final)[2]){
count.missing[i] <- count(is.na(pmesi.final)[,i])
}
count.missing <- vector(0, dim(pmesi.final)[2])
count.missing <- vec(0, dim(pmesi.final)[2])
count.missing <- rep(NA, dim(pmesi.final)[2])
for i in (1:dim(pmesi.final)[2]){
count.missing[i] <- count(is.na(pmesi.final)[,i])
}
for i in (1:dim(pmesi.final)[2]){
1:dim(pmesi.final)[2]
for i in (1:dim(pmesi.final)[2]){
count.missing[i] <- count(is.na(pmesi.final[,i]))
count.missing[i] <- sum(is.na(pmesi.final[,i]))
for i in (1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
for i in (1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
for i in (1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
i=1
pmesi.final[,i]
sum(is.na(pmesi.final[,i]))
count.missing[i] <- sum(is.na(pmesi.final[,i]))
for i in (1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
for (i in 1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
plot(count.missing)
count.missing > 500
table(count.missing > 500)
table(count.missing > 170)
table(count.missing > 1)
table(count.missing > 170)
# remove variables with more than 170 missing entries
170/6132
# remove variables with more than 170 missing entries
data = pmesi.final[,-count.missing>170]
-count.missing>170
count.missing>170
# remove variables with more than 170 missing entries
data = pmesi.final[,-c(count.missing>170)]
c(count.missing>170)
# remove variables with more than 170 missing entries
data = pmesi.final[,count.missing<170]
table(complete.cases(data))
sum(is.na(data$`Highest Level of Conflict Intensity`))
data$`Highest Level of Conflict Intensity`[is.na(data$`Highest Level of Conflict Intensity`)] <- 0
sum(is.na(data$`Highest Level of Conflict Intensity`))
count.missing2 <- rep(NA, dim(data)[2])
for (i in 1:dim(data)[2]){
count.missing2[i] <- sum(is.na(data[,i]))
}
plot(count.missing)
plot(count.missing2)
# KNN Imputation
rows <- nrow(data)
data.imputed <- knnImputation(data,k=200,scale=T,meth="weighAvg")
data.imputed <- knnImputation(data,k=200,scale=T,meth="weighAvg")
# KNN Imputation
install.packages("DMwR2")
# KNN Imputation
#install.packages("DMwR2")
library(DMwR2)
data.imputed <- knnImputation(data,k=200,scale=T,meth="weighAvg")
data.imputed <- knnImputation(data,k=100,scale=T,meth="weighAvg")
data.imputed <- knnImputation(data,k=50,scale=T,meth="weighAvg")
data.imputed <- knnImputation(data,k=10,scale=T,meth="weighAvg")
data.imputed <- knnImputation(data,k=500,scale=T,meth="weighAvg")
data.imputed <- knnImputation(data,k=1000,scale=T,meth="weighAvg")
data.imputed <- data
for (i in 1:99){
selection <- (rows-colSums(is.na(data)))/rows > (100-i)/100
data.impute <- data[,selection]
data.loc <- colnames(data.impute)
print(c(i,length(data.loc)))
data.impute <- knnImputation(data.impute,k=1000,scale=T,meth="weighAvg")
data.imputed[,data.loc] <- data.impute
}
data.impute <- knnImputation(data.impute,k=300,scale=T,meth="weighAvg")
data.impute <- knnImputation(data.impute,k=100,scale=T,meth="weighAvg")
complete.cases(data)
table(complete.cases(data))
data <- data[-complete.cases(data),]
data <- data[-complete.cases(data),]
data <- data[-complete.cases(data)==TRUE,]
complete <- completed.cases(data)
data <- data[complete,]
complete <- completed.cases(data)
completed.cases(data)
complete <- complete.cases(data)
# remove variables with more than 170 missing entries
data = pmesi.final[,count.missing<170]
table(complete.cases(data))
# NAs in HLCI assume are zero
sum(is.na(data$`Highest Level of Conflict Intensity`))
data$`Highest Level of Conflict Intensity`[is.na(data$`Highest Level of Conflict Intensity`)] <- 0
# NAs in HLCI assume are zero
sum(is.na(data$`Highest Level of Conflict Intensity`))
count.missing2 <- rep(NA, dim(data)[2])
for (i in 1:dim(data)[2]){
count.missing2[i] <- sum(is.na(data[,i]))
}
plot(count.missing2)
complete <- complete.cases(data)
data <- data[complete,]
count.missing2 <- rep(NA, dim(data)[2])
for (i in 1:dim(data)[2]){
count.missing2[i] <- sum(is.na(data[,i]))
}
plot(count.missing2)
plot(is.na(pmesi.final))
is.na(pmesi.final)
plot(count.missing2)
save(data, file="data_complete.csv")
write.csv(data, file="data_complete.csv")
age = c(25,35,45,20,35,52,23,40,60,48,33,48)
loan = c(40000,60000,80000,20000,120000,18000,95000,62000,100000,220000,150000,142000)
loan
age.norm = (max(age)-age)/max(age)
plot(age.norm)
max(age)
age.norm = (age-min(age))/(max(age)-min(age))
plot(age.norm)
loan.norm = (loan-min(loan))/(max(loan)-min(loan))
plot(loan.norm)
plot(age.norm)
plot(loan.norm)
age.norm
loan.norm = (loan-min(loan))/(max(loan)-min(loan))
plot(loan.norm)
loan.norm
dist = sqrt(age.norm^2 + loan.norm^2)
dist = sqrt((age.norm[10]-age.norm)^2 + (laon.norm[10]-loan.norm)^2)
dist = sqrt((age.norm[10]-age.norm)^2 + (loan.norm[10]-loan.norm)^2)
dist
dist1 = sqrt((age.norm[10]-age.norm)^2 + (loan.norm[10]-loan.norm)^2)
dist10 = sqrt((age.norm[10]-age.norm)^2 + (loan.norm[10]-loan.norm)^2)
dist12 = sqrt((age.norm[12]-age.norm)^2 + (loan.norm[12]-loan.norm)^2)
cbind(t(dist10),t(dist12))
dist = cbind(t(dist10),t(dist12))
dist
t(dist10)
source('~/.active-rstudio-document', echo=TRUE)
dist
min(dist10,2)
order(dist10)
order(dist12)
plot(age.norm,loan.norm)
default = c(N,N,N,N,N,N,Y,Y,Y,Y,Y,U)
plot(age.norm,loan.norm,color=default)
default = c(N,N,N,N,N,N,Y,Y,Y,Y,Y,U)
default = c("N","N","N","N","N","N","Y","Y","Y","Y","Y","U")
plot(age.norm,loan.norm,color=default)
library(ggplot2)
df = cbind(age,age.norm,loan,loan.norm,defualt)
ggplot2.scatterplot(data=df,xName='age',yName='laon amount',
groupName='default', size=3,
backgroundColor="white",
groupColors=c('#999999','#E69F00', '#56B4E9'))
library(ggplot2)
ggplot2.scatterplot(data=df,xName='age',yName='laon amount',
groupName='default', size=3,
backgroundColor="white",
groupColors=c('#999999','#E69F00', '#56B4E9'))
df = cbind(age,age.norm,loan,loan.norm,defualt)
default = c("N","N","N","N","N","N","Y","Y","Y","Y","Y","U")
df = cbind(age,age.norm,loan,loan.norm,defualt)
df = cbind(age,age.norm,loan,loan.norm,default)
library(ggplot2)
ggplot2.scatterplot(data=df,xName='age',yName='laon amount',
groupName='default', size=3,
backgroundColor="white",
groupColors=c('#999999','#E69F00', '#56B4E9'))
ggplot2(data=df,xName='age',yName='laon amount',
groupName='default', size=3,
backgroundColor="white",
groupColors=c('#999999','#E69F00', '#56B4E9'))
load("pmesi.RData")
sum(is.na(pmesi.final))*100/(dim(pmesi.final)[1]*dim(pmesi.final)[2])
sum(is.na(pmesi.final$`Highest Level of Conflict Intensity`))
table(complete.cases(pmesi.final))
count.missing <- rep(NA, dim(pmesi.final)[2])
for (i in 1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
plot(count.missing)
table(count.missing > 170)
# remove variables with more than 170 missing entries
data = pmesi.final[,count.missing<170]
table(complete.cases(data))
plot(count.missing)
for (i in 1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
plot(count.missing)
table(count.missing > 170)
# remove variables with more than 170 missing entries
data = pmesi.final[,count.missing<170]
table(complete.cases(data))
# NAs in HLCI assume are zero
sum(is.na(data$`Highest Level of Conflict Intensity`))
data$`Highest Level of Conflict Intensity`[is.na(data$`Highest Level of Conflict Intensity`)] <- 0
count.missing2 <- rep(NA, dim(data)[2])
for (i in 1:dim(data)[2]){
count.missing2[i] <- sum(is.na(data[,i]))
}
plot(count.missing2)
complete <- complete.cases(data)
data <- data[complete,]
view(data)
View(data)
sum(is.na(data))
load("pmesi.RData")
sum(is.na(pmesi.final))*100/(dim(pmesi.final)[1]*dim(pmesi.final)[2])
sum(is.na(pmesi.final$`Highest Level of Conflict Intensity`))
table(complete.cases(pmesi.final))
count.missing <- rep(NA, dim(pmesi.final)[2])
for (i in 1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
plot(count.missing)
table(count.missing > 170)
# remove variables with more than 170 missing entries
data = pmesi.final[,count.missing<170]
table(complete.cases(data))
# NAs in HLCI assume are zero
sum(is.na(data$`Highest Level of Conflict Intensity`))
data$`Highest Level of Conflict Intensity`[is.na(data$`Highest Level of Conflict Intensity`)] <- 0
count.missing2 <- rep(NA, dim(data)[2])
for (i in 1:dim(data)[2]){
count.missing2[i] <- sum(is.na(data[,i]))
}
plot(count.missing2)
which(is.na(data[,5]))
View(data)
data[which(is.na(data[,5])),1:5]
table(is.na(data[2269,]))
#Naive Bayes
install.packages("e1071")
#Naive Bayes
#install.packages("e1071")
library(e1071)
repeating_sequence <- rep.int(seq_len(nrow(data)), data$`Highest Level of Conflict Intensity`)
data <- data[repeating_sequence,]
repeating_sequence
data$`Highest Level of Conflict Intensity` = NULL
data.titanic = as.data.frame(data("Titanic"))
data("Titanic")
data.titanic = as.data.frame(Titanic)
load("pmesi.RData")
sum(is.na(pmesi.final))*100/(dim(pmesi.final)[1]*dim(pmesi.final)[2])
sum(is.na(pmesi.final$`Highest Level of Conflict Intensity`))
table(complete.cases(pmesi.final))
count.missing <- rep(NA, dim(pmesi.final)[2])
for (i in 1:dim(pmesi.final)[2]){
count.missing[i] <- sum(is.na(pmesi.final[,i]))
}
plot(count.missing)
table(count.missing > 170)
# remove variables with more than 170 missing entries
data = pmesi.final[,count.missing<170]
table(complete.cases(data))
# NAs in HLCI assume are zero
sum(is.na(data$`Highest Level of Conflict Intensity`))
data$`Highest Level of Conflict Intensity`[is.na(data$`Highest Level of Conflict Intensity`)] <- 0
count.missing2 <- rep(NA, dim(data)[2])
for (i in 1:dim(data)[2]){
count.missing2[i] <- sum(is.na(data[,i]))
}
plot(count.missing2)
complete <- complete.cases(data)
data <- data[complete,]
count.missing2 <- rep(NA, dim(data)[2])
for (i in 1:dim(data)[2]){
count.missing2[i] <- sum(is.na(data[,i]))
}
plot(count.missing2)
#Naive Bayes
#install.packages("e1071")
library(e1071)
Naive_Bayes_Model <- naiveBayes(`Highest Level of Conflict Intensity` ~., data = data)
Naive_Bayes_Model
View(Naive_Bayes_Model)
naiveBayes.default(x=X,y=Y,laplace=laplace)
summary(data$`Urban population growth (annual %)`)
Naive_Bayes_Model[["tables"]][["Year"]]
data("Titanic")
Titanic_df <- as.data.frame(Titanic)
repeating_sequence <- rep.int(seq_len(nrow(Titanic_df)), Titanic_df$Freq)
Titanic_dataset <- Titanic_df[repeating_sequence]
Titanic_dataset <- Titanic_df[repeating_sequence,]
Titanic_dataset$Freq = NULL
Naive_Bayes_Model <- naiveBayes(Survived ~., data=Titanic_dataset)
Naive_Bayes_Model
Naive_Bayes_Model[1]
Naive_Bayes_Model <- naiveBayes(`Highest Level of Conflict Intensity` ~., data = data)
Naive_Bayes_Model
Naive_Bayes_Model[1]
Naive_Bayes_Model <- naiveBayes(Survived ~., data=Titanic_dataset)
Naive_Bayes_Model
Naive_Bayes_Model <- naiveBayes(`Highest Level of Conflict Intensity` ~., data = data)
Naive_Bayes_Model[1:3]
Naive_Bayes_Model[0]
Naive_Bayes_Model[1]
Naive_Bayes_Model[2]
Naive_Bayes_Model[2,1]
Naive_Bayes_Model[2]
Naive_Bayes_Model[4]
Naive_Bayes_Model <- naiveBayes(Class ~., data=Titanic_dataset)
Naive_Bayes_Model
Naive_Bayes_Model <- naiveBayes(Country ~., data = data)
Naive_Bayes_Model
# PCA
library(factoextra)
# PCA
install.packages("factoextra")
# PCA
#install.packages("factoextra")
library(factoextra)
PCAdata <- data
prin_comp <- prcomp(data, scale.=T)
biplot(prin_comp, scale=0)
prin_comp <- prcomp(data[-2:3], scale.=T)
prin_comp <- prcomp(data[-c(2:3)], scale.=T)
biplot(prin_comp, scale=0)
std_dev <- prin_comp$sdev
pr_var <- std_dev^2
pr_varex <- pr_var/sum(pr_var)
plot(prop_varex, xlab = "Principal Component", ylab = "Proportion of VAriance Explained", type = "b")
plot(pr_varex, xlab = "Principal Component", ylab = "Proportion of VAriance Explained", type = "b")
plot(cumsum(pr_varex), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", type="b")
fviz_eig(prin_comp)
fviz_pca_ind(prin_comp, col.ind = "cos2", gradient.cols = c("#00AFBB","#E7B800","#FC4E07"), repel=TRUE)
#k means clustering
for (i in 2:880){
data.norm[,i] <- (data[,i]-mean(data[,i]))/std_dev(data[,i])
}
#k means clustering
for (i in 4:880){
data.norm[,i] <- (data[,i]-mean(data[,i]))/std_dev(data[,i])
}
data.norm[,(i-3)] <- (data[,i]-mean(data[,i]))/std_dev(data[,i])
std_dev(data[,4])
?sd
data.norm[,(i-3)] <- (data[,i]-mean(data[,i]))/sd(data[,i])
data.norm[,(i-3)] <- (as.numeric(data[,i])-as.numeric(mean(data[,i])))/as.numeric(sd(data[,i]))
as.numeric(data[,i])
data[,i]
as.numeric(data[,i])
data[,i]
mean(data[,i])
summary(data[,i])
mean(data[,i])
mean(as.numeric(data[,i]))
mean(as.vector(data[,i]))
sd(data[,i])
dist_data <- dist(data[-c(1:3)])
hc_data <- hclust(dist_data, method="complete")
clusters_k4 <- cutree(hc_data, k=4)
lineup_k2_complete <- mutate(lineup,cluster=clusters_k2)
clusters_k4
view(clusters_k4)
levels(dist_data)
factors(dist_data)
levels(as.factor(dist_data))
table(dist_data)
table(clusters_k4)
clusters_k4 <- cutree(hc_data, k=3)
lineup_k2_complete <- mutate(lineup,cluster=clusters_k2)
library(dendextend)
dend_data <- as.dendogram(hc_data)
dend_data <- as.dendrogram(hc_data)
dend_colored <- color_branches(dend_data, h=15)
plot(dend_colored)
clusters_k4 <- cutree(hc_data, k=2)
dend_data <- as.dendrogram(hc_data)
dend_colored <- color_branches(dend_data, h=6e16)
plot(dend_colored)
dend_colored <- color_branches(dend_data, h=4e16)
plot(dend_colored)
dend_colored <- color_branches(dend_data, h=2e16)
plot(dend_colored)
plot(dend_colored)
clusters <- kmeans(data[-c(1:3),])
clusters <- kmeans(data[-c(1:3),],3)
